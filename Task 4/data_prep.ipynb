{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69dbae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION NOTEBOOK\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f9b662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Department</th>\n",
       "      <th>PositionTitle</th>\n",
       "      <th>Salary</th>\n",
       "      <th>HireDate</th>\n",
       "      <th>Benefits_Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>John Smith</td>\n",
       "      <td>Police</td>\n",
       "      <td>Police Officer I</td>\n",
       "      <td>55000</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Jane Doe</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>60000.5</td>\n",
       "      <td>2014/03/15</td>\n",
       "      <td>14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Peter Jones</td>\n",
       "      <td>Parks &amp; Rec</td>\n",
       "      <td>Parks Maintenance</td>\n",
       "      <td>52000</td>\n",
       "      <td>2018-05-22</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Sarah Lee</td>\n",
       "      <td>Public Works</td>\n",
       "      <td>Sanitation Worker</td>\n",
       "      <td>48000.75</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Accountant I</td>\n",
       "      <td>65000</td>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeID         Name    Department      PositionTitle    Salary  \\\n",
       "0        1001   John Smith        Police   Police Officer I     55000   \n",
       "1        1002     Jane Doe          Fire        Firefighter   60000.5   \n",
       "2        1003  Peter Jones   Parks & Rec  Parks Maintenance     52000   \n",
       "3        1004    Sarah Lee  Public Works  Sanitation Worker  48000.75   \n",
       "4        1005          NaN       Finance       Accountant I     65000   \n",
       "\n",
       "     HireDate  Benefits_Cost  \n",
       "0  2015-01-10          12500  \n",
       "1  2014/03/15          14000  \n",
       "2  2018-05-22          11000  \n",
       "3  2019-11-01          10500  \n",
       "4  2016-07-20          15000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load messy dataset\n",
    "df = pd.read_csv(\"messy_data.csv\")  # replace with your file path\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d2e354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   EmployeeID     15 non-null     int64 \n",
      " 1   Name           14 non-null     object\n",
      " 2   Department     15 non-null     object\n",
      " 3   PositionTitle  14 non-null     object\n",
      " 4   Salary         15 non-null     object\n",
      " 5   HireDate       15 non-null     object\n",
      " 6   Benefits_Cost  15 non-null     int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 972.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EmployeeID       0\n",
       "Name             1\n",
       "Department       0\n",
       "PositionTitle    1\n",
       "Salary           0\n",
       "HireDate         0\n",
       "Benefits_Cost    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect dataset\n",
    "df.info()        # column types and missing values\n",
    "df.describe()    # summary statistics\n",
    "df.isnull().sum()  # count missing values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4016f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shafia\\AppData\\Local\\Temp\\ipykernel_26140\\2365776739.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Shafia\\AppData\\Local\\Temp\\ipykernel_26140\\2365776739.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Shafia\\AppData\\Local\\Temp\\ipykernel_26140\\2365776739.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing numeric values with median\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737b8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using Z-score\n",
    "numeric_df = df[num_cols]\n",
    "z_scores = np.abs(stats.zscore(numeric_df))\n",
    "df = df[(z_scores < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "548d0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to appropriate types\n",
    "if 'date_col' in df.columns:\n",
    "    df['date_col'] = pd.to_datetime(df['date_col'])\n",
    "\n",
    "if 'category_col' in df.columns:\n",
    "    df['category_col'] = df['category_col'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8355decc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed! Cleaned dataset saved as 'cleaned_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save cleaned dataset for modeling\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "print(\"Data cleaning completed! Cleaned dataset saved as 'cleaned_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eea3fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot data if needed: example of summarizing values by category over time\n",
    "if 'date_col' in df.columns and 'category_col' in df.columns and 'value' in df.columns:\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='date_col',          # rows by date\n",
    "        columns='category_col',    # columns by category\n",
    "        values='value',            # aggregate value\n",
    "        aggfunc='sum'              # sum values per group\n",
    "    )\n",
    "    df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d34eea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a multi-index (example: region and year)\n",
    "if 'region' in df.columns and 'year' in df.columns:\n",
    "    df.set_index(['region', 'year'], inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d855a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets using merge_asof for time-aligned joins\n",
    "# Example: merging df1 and df2 on 'date_col'\n",
    "# df1 and df2 must be sorted by date\n",
    "if 'df1' in globals() and 'df2' in globals() and 'date_col' in df1.columns:\n",
    "    df_merged = pd.merge_asof(\n",
    "        df1.sort_values('date_col'),\n",
    "        df2.sort_values('date_col'),\n",
    "        on='date_col',\n",
    "        direction='nearest'  # nearest date match\n",
    "    )\n",
    "    df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acfd348a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized dataset saved as 'normalized_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save normalized dataset\n",
    "df.to_csv(\"normalized_data.csv\", index=True)  # keep multi-index if applied\n",
    "print(\"Normalized dataset saved as 'normalized_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb2930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: creating a squared term for a numeric feature\n",
    "if 'feature' in df.columns:\n",
    "    df['feature_sq'] = df['feature'] ** 2\n",
    "    df[['feature', 'feature_sq']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0a9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: interaction between two numeric features\n",
    "if 'feature1' in df.columns and 'feature2' in df.columns:\n",
    "    df['interaction'] = df['feature1'] * df['feature2']\n",
    "    df[['feature1', 'feature2', 'interaction']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118cf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to dummy variables (one-hot encoding)\n",
    "cat_cols = df.select_dtypes(include='category').columns\n",
    "if len(cat_cols) > 0:\n",
    "    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c9722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: mean of target per group\n",
    "if 'group_col' in df.columns and 'target' in df.columns:\n",
    "    df['mean_by_group'] = df.groupby('group_col')['target'].transform('mean')\n",
    "    df[['group_col', 'target', 'mean_by_group']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe89da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed! Dataset saved as 'prepared_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fully prepared dataset\n",
    "df.to_csv(\"prepared_data.csv\", index=False)\n",
    "print(\"Feature engineering completed! Dataset saved as 'prepared_data.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
